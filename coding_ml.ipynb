{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "590d2eff-3f5b-49d5-b9b2-2dec5a598c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min element: 1\n",
      "Popping elements:\n",
      "1\n",
      "3\n",
      "5\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "\n",
    "class MinHeap:\n",
    "    def __init__(self):\n",
    "        self.heap = []\n",
    "\n",
    "    def push(self, val):\n",
    "        heapq.heappush(self.heap, val)\n",
    "\n",
    "    def pop(self):\n",
    "        return heapq.heappop(self.heap)\n",
    "\n",
    "    def peek(self):\n",
    "        return self.heap[0]\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.heap)\n",
    "\n",
    "# Example usage:\n",
    "min_heap = MinHeap()\n",
    "min_heap.push(5)\n",
    "min_heap.push(3)\n",
    "min_heap.push(8)\n",
    "min_heap.push(1)\n",
    "\n",
    "print(\"Min element:\", min_heap.peek())  # Output: 1\n",
    "\n",
    "print(\"Popping elements:\")\n",
    "while min_heap.size() > 0:\n",
    "    print(min_heap.pop())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a236b6d6-bb50-40d6-b557-bf48beabfdbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next task: Task 2\n",
      "Processing tasks:\n",
      "Processing: Task 2\n",
      "Processing: Task 3\n",
      "Processing: Task 1\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "\n",
    "class PriorityQueue:\n",
    "    def __init__(self):\n",
    "        self.heap = []\n",
    "        self.index = 0\n",
    "\n",
    "    def push(self, priority, item):\n",
    "        heapq.heappush(self.heap, (priority, self.index, item))\n",
    "        self.index += 1\n",
    "\n",
    "    def pop(self):\n",
    "        return heapq.heappop(self.heap)[-1]\n",
    "\n",
    "    def peek(self):\n",
    "        return self.heap[0][-1]\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.heap)\n",
    "\n",
    "# Example usage:\n",
    "priority_queue = PriorityQueue()\n",
    "priority_queue.push(3, 'Task 1')\n",
    "priority_queue.push(1, 'Task 2')\n",
    "priority_queue.push(2, 'Task 3')\n",
    "\n",
    "print(\"Next task:\", priority_queue.peek())  # Output: 'Task 2'\n",
    "\n",
    "print(\"Processing tasks:\")\n",
    "while priority_queue.size() > 0:\n",
    "    print(\"Processing:\", priority_queue.pop())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd75606c-4f92-477b-8f33-f2ebce718bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListNode:\n",
    "    def __init__(self, val=0, next=None):\n",
    "        self.val = val\n",
    "        self.next = next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27c04d14-45e8-4a75-8cd5-189806658506",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ListNode(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be31af29-e0c2-4efc-9644-78f14cd5baf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None\n"
     ]
    }
   ],
   "source": [
    "print(result.val, result.next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a2d495-2fbb-45a8-b18f-14ed80256f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here. Please read `IMPORTANT NOTES` section carefully before you proceed.\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "\n",
    "# Load the training data\n",
    "data_train = pd.read_csv(\"train.csv\", header=None)\n",
    "# print(data_train.shape)\n",
    "\n",
    "# Separate features (first 294 columns) and labels (last 6 columns)\n",
    "X = data_train.iloc[:, :294]  # Features\n",
    "y = data_train.iloc[:, 294:]  # Labels (six binary columns)\n",
    "\n",
    "# Load the test data\n",
    "data_test = pd.read_csv(\"test.csv\", header=None)\n",
    "# print(data_test.shape)\n",
    "\n",
    "# Train individual classifiers for each of the six binary labels\n",
    "predictions = []\n",
    "for i in range(6):  # There are 6 scene types (binary outputs)\n",
    "    # Extract the target column for the current scene type\n",
    "    y_scene = y.iloc[:, i]\n",
    "    \n",
    "    # Split data into train and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y_scene, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Use RandomForestClassifier as the model\n",
    "    model = RandomForestClassifier(n_estimators=80, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # # Try cross-validaiton, but it is Time limit exceeded.\n",
    "    # # Perform cross-validation and predict on the training set\n",
    "    # y_train_pred_proba = cross_val_predict(model, X, y_scene, cv=5, method='predict_proba')[:, 1]  # Probabilities for class \"1\"\n",
    "    # cross_val_accuracy = cross_val_score(model, X, y_scene, cv=5, scoring='accuracy')\n",
    "    # print(f\"Scene {i+1} cross-validation accuracy: {np.mean(cross_val_accuracy):.4f}\")\n",
    "    # # Train the model on the entire training data\n",
    "    # model.fit(X, y_scene)\n",
    "    \n",
    "    # Validate the model\n",
    "    y_val_pred_proba = model.predict_proba(X_val)[:, 1]  # Probabilities for class \"1\"\n",
    "    y_val_pred = (y_val_pred_proba >= 0.55).astype(int)  # Apply 55% threshold\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"Accuracy for scene {i+1}: {acc:.4f}\")\n",
    "    \n",
    "    # Predict on the test data\n",
    "    y_test_pred_proba = model.predict_proba(data_test)[:, 1]  # Probabilities for class \"1\"\n",
    "    y_test_pred = (y_test_pred_proba >= 0.55).astype(int)     # Apply 55% threshold\n",
    "    # print(y_test_pred[:5])\n",
    "    predictions.append(y_test_pred)\n",
    "    # print(predictions[:5])\n",
    "    \n",
    "    \n",
    "# Combine predictions for all six labels\n",
    "predictions = np.array(predictions).T  # Transpose to get predictions per row\n",
    "# print(predictions)\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions, columns=[f\"Scene_{i+1}\" for i in range(6)])\n",
    "predictions_df.to_csv(\"prediction.csv\", index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
